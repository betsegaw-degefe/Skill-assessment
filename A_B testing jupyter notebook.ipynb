{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Hypothesis \n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "### Experiment Details\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Choice \n",
    "### Invariant Metrics: \n",
    "number of cookies, number of clicks, click-through-probability\n",
    "\n",
    "| Metric Name  | Metric Formula  | $Dmin$  | Notation |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Number of Cookies in Course Overview Page  | # unique daily cookies on page | 3000 cookies  | $C_k$ |\n",
    "| Number of Clicks on Free Trial Button  | # unique daily cookies who clicked  | 240 clicks | $C_l$ |\n",
    "| Free Trial button Click-Through-Probability  | $\\frac{C_l}{C_k}$ | 0.01  | $CTP$ | \n",
    "\n",
    "### Evaluation Metrics: \n",
    "gross conversion, retention, net conversion\n",
    "\n",
    "| Metric Name  | Metric Formula  | $Dmin$  | Notation |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Gross Conversion   |  $\\frac{enrolled}{C_l}$  | 0.01  | $Conversion_{Gross}$ |\n",
    "| Retention   | $\\frac{paid}{enrolled}$  | 0.01  | $Retention$ |\n",
    "| Net Conversion  |  $\\frac{paid}{C_l}$  | 0.0075 | $Conversion_{Net}$ |\n",
    "\n",
    "#### Invariant Metrics \n",
    "Invariant metrics were chosen due to their expected property. One would expect similiar distribution into control and experiment for the following metrics.\n",
    "\n",
    "###### Number of Cookies: \n",
    "The number of unique cookies to visit the course overview page. This is the unit of diversion and even distribution amongst the control and experiment groups is expected. It is therefore appropriate as an invariant metric.\n",
    "\n",
    "###### Number of Clicks: \n",
    "The number of users (tracked as unique cookies at this stage) to click the free trial buttion. This is appropriate as an invariant metric but not an evaluation metrice. Equal distribution amongst the experiment and control groups would be expected since at this point in the funnel the experience is the same for all users and therefore elements of the experiment would not be expected to impact clicking the \"start free trial\" button.\n",
    "\n",
    "##### Click-through-probability: \n",
    "Unique cookies to click the \"start free trial\" button per unique cookies to view the course overview page. Equal distribution amongst the experiment and control groups would be expected since at this point in the funnel the experience is the same for all users and therefore elements of the experiment would not be expected to impact clicking the \"start free trial\" button.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "Evaluation metrics were chosen since there is the possibility of different distributions between experiment and control groups as a function of the experiment. Each evaluation metric is associated with a minimum difference (dmin) that must be observed for consideration in the decision to launch the experiment. The ultimate goal is to minimize student frustration and satisfaction and to most effectively use limited coaching resources. \n",
    "\n",
    "##### Gross Conversion: \n",
    "This is the number of user-ids to complete checkout and enroll in the free trial per unique cookie to click the \"start free trial\" button. dmin = 0.01\n",
    "\n",
    "##### Retention: \n",
    "This is the number of user-ids to remain enrolled past the 14 day trial period, making at least one payment, per number of user-ids to complete checkout. The practical minimum difference (dmin) = 0.01\n",
    "\n",
    "##### Net Conversion: \n",
    "this is the number of user-ids to remain enrolled past the 14 day trial, making at least one payment, per the number of unique cookies to click the \"start free trial\" button. dmin = 0.0075\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Baseline conversion value\n",
    "From the data given we have the following estimates\n",
    "\n",
    "| Item | Description  | Estimator  |\n",
    "|:-:|:-:|:-:|\n",
    "| Number of cookies | Daily unique cookies to view course overview page  | 40,000  |\n",
    "| Number of clicks | Daily unique cookies to click Free Trial button  | 3,200 |\n",
    "| Number of enrollments | Free Trial enrollments per day  | 660  |\n",
    "| CTP | CTP on Free Trial button  | 0.08  |\n",
    "| Gross Conversion | Probability of enrolling, given a click  | 0.20625  |\n",
    "| Retention | Probability of payment, given enrollment  | 0.53  |\n",
    "| Net Conversion | Probability of payment, given click  | 0.109313 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placing the estimators into a dictionary\n",
    "baseline = {\"Cookies\":40000,\"Clicks\":3200,\"Enrollments\":660,\"CTP\":0.08,\"GrossConversion\":0.20625,\n",
    "           \"Retention\":0.53,\"NetConversion\":0.109313}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Standard Deviation\n",
    "Once we collected these estimates, we should estimate the standard deviation of a metric, this is computed for sample size calculations and confidence intervals for our results. \n",
    "\n",
    "#### Scaling Collected Data\n",
    "For all the calculations to follow we need to scale our collected counts estimates of metrics with the sample size we specified for variance estimation. In this case, from 40000 unique cookies to visit the course overview page per day, to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cookies': 5000,\n",
       " 'Clicks': 400.0,\n",
       " 'Enrollments': 82.5,\n",
       " 'CTP': 0.08,\n",
       " 'GrossConversion': 0.20625,\n",
       " 'Retention': 0.53,\n",
       " 'NetConversion': 0.109313}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale The counts estimates\n",
    "baseline[\"Cookies\"] = 5000\n",
    "baseline[\"Clicks\"]=baseline[\"Clicks\"]*(5000/40000)\n",
    "baseline[\"Enrollments\"]=baseline[\"Enrollments\"]*(5000/40000)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Estimating Analytically <a class=\"anchor\" id=\"estimate\"></a>\n",
    "In order to estimate variance analytically, we can assume metrics which are probabilities ($\\hat{p}$) are binomially distributed, so we can use this formula for the standard deviation: <br>\n",
    "<center><font size=\"4\">$SD=\\sqrt{\\frac{\\hat{p}*(1-\\hat{p})}{n}}$</font></center><br>\n",
    "\n",
    "\n",
    "$\\hat{p}$ - baseline probability of the event to occur <br>\n",
    "$ n $ - sample size <br>\n",
    "\n",
    "\n",
    "* **Gross Conversion** - The baseline probability for Gross Conversion can be calculated by the number of users to enroll in a free trial divided by the number of cookies clicking the free trial. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion={}\n",
    "GrossConversion[\"d_min\"]=0.01\n",
    "GrossConversion[\"p\"]=baseline[\"GrossConversion\"]\n",
    "GrossConversion[\"n\"]=baseline[\"Clicks\"]\n",
    "GrossConversion[\"StansardDeviation\"]=round(mt.sqrt((GrossConversion[\"p\"]*(1-GrossConversion[\"p\"]))/GrossConversion[\"n\"]),4)\n",
    "GrossConversion[\"StansardDeviation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Retention** - The baseline probability for retention is the number of paying users (enrolled after 14 free days) divided by the number of total enrolled users. The sample size is the number of enrolled users. In this case, unit of diversion is not equal to unit of analysis (users who enrolled) so an analytical estimation is not enough - if we had the data for these estimates, we would want to estimate this variance empirically as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0549"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retention={}\n",
    "Retention[\"d_min\"]=0.01\n",
    "Retention[\"p\"]=baseline[\"Retention\"]\n",
    "Retention[\"n\"]=baseline[\"Enrollments\"]\n",
    "Retention[\"StansardDeviation\"]=round(mt.sqrt((Retention[\"p\"]*(1-Retention[\"p\"]))/Retention[\"n\"]),4)\n",
    "Retention[\"StansardDeviation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Net Conversion** - The baseline probability for the net conversion is the number of paying users divided by the number of cookies that clicked the free trial button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NetConversion={}\n",
    "NetConversion[\"d_min\"]=0.0075\n",
    "NetConversion[\"p\"]=baseline[\"NetConversion\"]\n",
    "NetConversion[\"n\"]=baseline[\"Clicks\"]\n",
    "NetConversion[\"StansardDeviation\"]=round(mt.sqrt((NetConversion[\"p\"]*(1-NetConversion[\"p\"]))/NetConversion[\"n\"]),4)\n",
    "NetConversion[\"StansardDeviation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Sizing\n",
    "Once we have estimated our metrics in the baseline, we can calculate the minimal number of samples we need so that our experiment will have enough statistical power, as well as siginificance.\n",
    "\n",
    "Given $\\alpha=0.05$ (significance level ) and $\\beta=0.2$ (power), we want to estimate how many total pageviews we need in the experiment. This amount will be divided into the two groups: control and experiment. \n",
    "\n",
    "The minimum sample size for control and experiment groups, which provides probability of Type I Error $\\alpha$, Power $1-\\beta$, detectable effect $d$ and baseline conversion rate $p$ (simple hypothesis $H_0 : P_{cont} - P_{exp} = 0$ against simple alternative $H_A : P_{cont} - P_{exp} = d$  is:\n",
    "\n",
    "<center> <font size=\"5\"> $n = \\frac{(Z_{1-\\frac{\\alpha}{2}}sd_1 + Z_{1-\\beta}sd_2)^2}{d^2}$</font>, with: <br><br>\n",
    "$sd_1 = \\sqrt{p(1-p)+p(1-p)}$<br><br>\n",
    "$sd_2 = \\sqrt{p(1-p)+(p+d)(1-(1-(p+d))}$ </center><br>\n",
    "\n",
    "Now, let's break down what inputs we need and which calculations still need to be made. Regarding inputs, we have all the data we need:\n",
    "Type 1 error ($\\alpha$), power ($1-\\beta$), detectable change ($d = D_{min}$) and baseline conversion rate (our $\\hat{p}$ ).\n",
    "What we need to calculate: \n",
    "* Get Z score for $1-\\frac{\\alpha}{2}$ and for $1-\\beta$\n",
    "* Get standard deviations 1 & 2, that is for both the baseline and for expected changed rate\n",
    "All these components will finally yield the number we need.\n",
    "\n",
    "### Get z-score critical value and Standard Deviations\n",
    "we can use python's `scipy.stats.norm` package to get all the required methods for normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_deviations(p,d):\n",
    "    sd1=mt.sqrt(2*p*(1-p))\n",
    "    sd2=mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n",
    "    x=[sd1,sd2]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs: required alpha value (alpha should already fit the required test)\n",
    "def get_z_score(alpha):\n",
    "    return norm.ppf(alpha)\n",
    "\n",
    "# Inputs p-baseline conversion rate which is our estimated p and d-minimum detectable change\n",
    "def get_standard_deviations(p,d):\n",
    "    sd1=mt.sqrt(2*p*(1-p))\n",
    "    sd2=mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n",
    "    sds=[sd1,sd2]\n",
    "    return sds\n",
    "\n",
    "# Inputs:sd1-sd for the baseline,sd2-sd for the expected change,alpha,beta,d-d_min,p-baseline estimate p\n",
    "def get_sampSize(sds,alpha,beta,d):\n",
    "    n=pow((get_z_score(1-alpha/2)*sds[0]+get_z_score(1-beta)*sds[1]),2)/pow(d,2)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sample Size per Metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrossConversion[\"d\"]=0.01\n",
    "Retention[\"d\"]=0.01\n",
    "NetConversion[\"d\"]=0.0075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Gross Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25835.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion[\"SampSize\"]=round(get_sampSize(get_standard_deviations(GrossConversion[\"p\"],GrossConversion[\"d\"]),0.05,0.2,GrossConversion[\"d\"]))\n",
    "GrossConversion[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total amount of samples per the Gross Conversion metric is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrossConversion[\"SampSize\"]=round(GrossConversion[\"SampSize\"]/0.08*2)\n",
    "GrossConversion[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39087.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retention[\"SampSize\"]=round(get_sampSize(get_standard_deviations(Retention[\"p\"],Retention[\"d\"]),0.05,0.2,Retention[\"d\"]))\n",
    "Retention[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we need 39,087 users who enrolled per group! We have to first convert this to cookies who clicked, and then to cookies who viewed the page, then finally to multipky by two for both groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574280991.7355372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Retention[\"SampSize\"]=Retention[\"SampSize\"]/0.08/0.20625*2\n",
    "Retention[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Net Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27413.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NetConversion[\"SampSize\"]=round(get_sampSize(get_standard_deviations(NetConversion[\"p\"],NetConversion[\"d\"]),0.05,0.2,NetConversion[\"d\"]))\n",
    "NetConversion[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, needing 27,413 cookies who click per group takes us all the way up to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NetConversion[\"SampSize\"]=NetConversion[\"SampSize\"]/0.08*2\n",
    "NetConversion[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all the way up to 685,325 cookies who view the page. This is more than what was needed for Gross Conversion, so this will be our number. Assuming we take 80% of each days pageviews, the data collection period for this experiment (the period in which the experiment is revealed) will be about 3 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Collected Data\n",
    "\n",
    "\n",
    "### Loading collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687        134.0      70.0\n",
       "1  Sun, Oct 12       9102     779        147.0      70.0\n",
       "2  Mon, Oct 13      10511     909        167.0      95.0\n",
       "3  Tue, Oct 14       9871     836        156.0     105.0\n",
       "4  Wed, Oct 15      10014     837        163.0      64.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use pandas to load datasets\n",
    "control=pd.read_csv(\"data/Control.csv\")\n",
    "experiment=pd.read_csv(\"data/Experiment.csv\")\n",
    "control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "These checks help verify that the experiment was conducted as expected and that other factors did not influence the data which we collected. This also makes sure that data collection was correct.\n",
    "\n",
    "We have 3 Invariant metrics:: \n",
    "* Number of Cookies in Course Overview Page\n",
    "* Number of Clicks on Free Trial Button\n",
    "* Free Trial button Click-Through-Probability\n",
    "\n",
    "Two of these metrics are simple counts like number of cookies or number of clicks and the third is a probability (CTP). We will use two different ways of checking whether these obsereved values are like we expect (if in fact the experiment was not damaged.\n",
    "\n",
    "#### Sanity Checks for differences between counts \n",
    "* **Number of cookies who viewed the course overview page** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pageviews in control: 345543\n",
      "number of Pageviewsin experiment: 344660\n"
     ]
    }
   ],
   "source": [
    "pageviews_cont=control['Pageviews'].sum()\n",
    "pageviews_exp=experiment['Pageviews'].sum()\n",
    "pageviews_total=pageviews_cont+pageviews_exp\n",
    "print (\"number of pageviews in control:\", pageviews_cont)\n",
    "print (\"number of Pageviewsin experiment:\" ,pageviews_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make sure this difference in amounts is not significant and is random and even like we expected. \n",
    "<br>\n",
    "We expect the amount of pageviews in the control group to be about a half (50%) of the total pageviews in both groups, so we can define a random variable with an easy to use distribution. <br>\n",
    "\n",
    "Using central limit theorem which approximate the binomial distribution to a normal distribution (when n is large enough) with a mean of $p$ and a standard deviation $\\sqrt{\\frac{p(1-p)}{N}}$\n",
    "<center> <font size=\"4\"> $ X$~$N( p,\\sqrt{\\frac{p(1-p)}{N}})$ </font></center>\n",
    "What we want to test is whether our observed $\\hat{p}$ (number of samples in control divided by total number of samples in both groups) is not significantly different than $p=0.5$. In order to do that we can calculate the margin of error acceptable at a 95% confidence level:\n",
    "<center> <font size=\"4\"> $ ME=Z_{1-\\frac{\\alpha}{2}}SD$ </font></center>\n",
    "\n",
    "<center> <font size=\"4\"> $ CI=[\\hat{p}-ME,\\hat{p}+ME]$ </font></center>\n",
    "When our obsereved $\\hat{p}$ is within this range, all is well and the test was passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4988 and 0.5012 ; Is 0.5006 inside this range?\n"
     ]
    }
   ],
   "source": [
    "p=0.5\n",
    "alpha=0.05\n",
    "p_hat=round(pageviews_cont/(pageviews_total),4)\n",
    "sd=mt.sqrt(p*(1-p)/(pageviews_total))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our observed $\\hat{p}$ is inside this range which means the difference in number of samples between groups is expected. So far so good, since this invariant metric sanity test passes!\n",
    "* **Number of cookies who clicked the Free Trial Button**\n",
    "We are going to address this count with the same strategy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4959 and 0.5041 ; Is 0.5005 inside this range?\n"
     ]
    }
   ],
   "source": [
    "clicks_cont=control['Clicks'].sum()\n",
    "clicks_exp=experiment['Clicks'].sum()\n",
    "clicks_total=clicks_cont+clicks_exp\n",
    "\n",
    "p_hat=round(clicks_cont/clicks_total,4)\n",
    "sd=mt.sqrt(p*(1-p)/clicks_total)\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far it still seems all is well with our experiment results. Now, for the final metric which is a probability.\n",
    "\n",
    "#### Sanity Checks for differences between probabilities <a class=\"anchor\" id=\"check_prob\"></a>\n",
    "* **Click-through-probability of the Free Trial Button**\n",
    "In this case, we want to make sure the proportion of clicks given a pageview (our observed CTP) is about the same in both groups (since this was not expected to change due to the experiment). In order to check this out we will calculate the CTP in each group and calculate a confidence interval for the expected difference between them. \n",
    "\n",
    "In other words, we expect to see no difference ($CTP_{exp}-CTP_{cont}=0$), with an acceptable margin of error, dictated by our calculated confidence interval. The changes we should notice are for the calculation of the standard error - which in this case is a pooled standard error.\n",
    "\n",
    "<center><font size=\"4\">$SD_{pool}=\\sqrt{\\hat{p_{pool}}(1-\\hat{p_{pool}}(\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})}$</font></center>\n",
    "with <br> <center><font size=\"5\"> $\\hat{p_{pool}}=\\frac{x_{cont}+x_{exp}}{N_{cont}+N_{exp}}$ </font></center>\n",
    "We should understand that CTP is a proportion in a population (amount of events x in a population n) like the amount of clicks out of the amount of pageviews.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between -0.0013 and 0.0013 ; Is 0.0001 within this range?\n"
     ]
    }
   ],
   "source": [
    "ctp_cont=clicks_cont/pageviews_cont\n",
    "ctp_exp=clicks_exp/pageviews_exp\n",
    "d_hat=round(ctp_exp-ctp_cont,4)\n",
    "p_pooled=clicks_total/pageviews_total\n",
    "sd_pooled=mt.sqrt(p_pooled*(1-p_pooled)*(1/pageviews_cont+1/pageviews_exp))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd_pooled,4)\n",
    "print (\"The confidence interval is between\",0-ME,\"and\",0+ME,\"; Is\",d_hat,\"within this range?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems this test has passed with flying colors as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining effect size\n",
    "The next step is looking at the changes between the control and experiment groups with regard to our evaluation metrics to make sure the difference is there, that it is statistically significant and most importantly practically significant (the difference is \"big\" enough to make the experimented change beneficial to the company).\n",
    "\n",
    "Now, all that is left is to measure for each evaluation metric, the difference between the values from both groups. Then, we compute the confidence interval for that difference and test whether or not this confidence interval is both statistically and practically significant.\n",
    "\n",
    "* **Gross Conversion**\n",
    "A metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_cont=control[\"Clicks\"].loc[control[\"Enrollments\"].notnull()].sum()\n",
    "clicks_exp=experiment[\"Clicks\"].loc[experiment[\"Enrollments\"].notnull()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -2.06 %\n",
      "Confidence Interval: [ -0.0292 , -0.012 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if -0.01 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "enrollments_cont=control[\"Enrollments\"].sum()\n",
    "enrollments_exp=experiment[\"Enrollments\"].sum()\n",
    "\n",
    "GC_cont=enrollments_cont/clicks_cont\n",
    "GC_exp=enrollments_exp/clicks_exp\n",
    "GC_pooled=(enrollments_cont+enrollments_exp)/(clicks_cont+clicks_exp)\n",
    "GC_sd_pooled=mt.sqrt(GC_pooled*(1-GC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "GC_ME=round(get_z_score(1-alpha/2)*GC_sd_pooled,4)\n",
    "GC_diff=round(GC_exp-GC_cont,4)\n",
    "print(\"The change due to the experiment is\",GC_diff*100,\"%\")\n",
    "print(\"Confidence Interval: [\",GC_diff-GC_ME,\",\",GC_diff+GC_ME,\"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",-GrossConversion[\"d_min\"],\"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result there was a change due to the experiment, that change was both statistically and practically significant. \n",
    "We have a negative change of 2.06%, when we were willing to accept any change greater than 1%. This means the Gross Conversion rate of the experiment group (the one exposed to the change, i.e. asked how many hours they can devote to studying) has decreased as expected by 2% and this change was significant. This means  less people enrolled in the Free Trial after due to the pop-up. \n",
    "* **Net Conversion** \n",
    "The hypothesis is the same as before just with net conversion instead of gross. At this point we expect the fraction of payers (out of the clicks) to decrease as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -0.49 %\n",
      "Confidence Interval: [ -0.0116 , 0.0018000000000000004 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if 0.0075 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "payments_cont=control[\"Payments\"].sum()\n",
    "payments_exp=experiment[\"Payments\"].sum()\n",
    "\n",
    "NC_cont=payments_cont/clicks_cont\n",
    "NC_exp=payments_exp/clicks_exp\n",
    "NC_pooled=(payments_cont+payments_exp)/(clicks_cont+clicks_exp)\n",
    "NC_sd_pooled=mt.sqrt(NC_pooled*(1-NC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "NC_ME=round(get_z_score(1-alpha/2)*NC_sd_pooled,4)\n",
    "NC_diff=round(NC_exp-NC_cont,4)\n",
    "print(\"The change due to the experiment is\",NC_diff*100,\"%\")\n",
    "print(\"Confidence Interval: [\",NC_diff-NC_ME,\",\",NC_diff+NC_ME,\"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",NetConversion[\"d_min\"],\"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we got a change size of less than a 0.5%, a very small decrease which is not statistically significant, and as such not practically significant.\n",
    "\n",
    "## Double check with Sign Tests \n",
    "In a sign test we get another angle at analyzing the results we got - we check if the trend of change we observed (increase or decrease) was evident in the daily data. We are goint to compute the metric's value per day and then count on how many days the metric was lower in the experiment group and this will be the number of succssesses for our binomial variable. Once this is defined we can look at the proportion of days of success out of all the available days.\n",
    "\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_cont           37\n",
       "Pageviews_cont      37\n",
       "Clicks_cont         37\n",
       "Enrollments_cont    23\n",
       "Payments_cont       23\n",
       "Date_exp            37\n",
       "Pageviews_exp       37\n",
       "Clicks_exp          37\n",
       "Enrollments_exp     23\n",
       "Payments_exp        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full=control.join(other=experiment,how=\"inner\",lsuffix=\"_cont\",rsuffix=\"_exp\")\n",
    "\n",
    "full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_cont           23\n",
       "Pageviews_cont      23\n",
       "Clicks_cont         23\n",
       "Enrollments_cont    23\n",
       "Payments_cont       23\n",
       "Date_exp            23\n",
       "Pageviews_exp       23\n",
       "Clicks_exp          23\n",
       "Enrollments_exp     23\n",
       "Payments_exp        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we only need the complete data records\n",
    "full=full.loc[full[\"Enrollments_cont\"].notnull()]\n",
    "full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_cont</th>\n",
       "      <th>Pageviews_cont</th>\n",
       "      <th>Clicks_cont</th>\n",
       "      <th>Enrollments_cont</th>\n",
       "      <th>Payments_cont</th>\n",
       "      <th>Date_exp</th>\n",
       "      <th>Pageviews_exp</th>\n",
       "      <th>Clicks_exp</th>\n",
       "      <th>Enrollments_exp</th>\n",
       "      <th>Payments_exp</th>\n",
       "      <th>GC</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_cont  Pageviews_cont  Clicks_cont  Enrollments_cont  Payments_cont  \\\n",
       "0  Sat, Oct 11            7723          687             134.0           70.0   \n",
       "1  Sun, Oct 12            9102          779             147.0           70.0   \n",
       "2  Mon, Oct 13           10511          909             167.0           95.0   \n",
       "3  Tue, Oct 14            9871          836             156.0          105.0   \n",
       "4  Wed, Oct 15           10014          837             163.0           64.0   \n",
       "\n",
       "      Date_exp  Pageviews_exp  Clicks_exp  Enrollments_exp  Payments_exp  GC  \\\n",
       "0  Sat, Oct 11           7716         686            105.0          34.0   0   \n",
       "1  Sun, Oct 12           9288         785            116.0          91.0   0   \n",
       "2  Mon, Oct 13          10480         884            145.0          79.0   0   \n",
       "3  Tue, Oct 14           9867         827            138.0          92.0   0   \n",
       "4  Wed, Oct 15           9793         832            140.0          94.0   0   \n",
       "\n",
       "   NC  \n",
       "0   0  \n",
       "1   1  \n",
       "2   0  \n",
       "3   0  \n",
       "4   1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need a 1 if the experiment value is greater than the control value=\n",
    "x=full['Enrollments_cont']/full['Clicks_cont']\n",
    "y=full['Enrollments_exp']/full['Clicks_exp']\n",
    "full['GC'] = np.where(x<y,1,0)\n",
    "# The same now for net conversion\n",
    "z=full['Payments_cont']/full['Clicks_cont']\n",
    "w=full['Payments_exp']/full['Clicks_exp']\n",
    "full['NC'] = np.where(z<w,1,0)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of cases for GC: 4 \n",
      " No. of cases for NC: 10 \n",
      " No. of total cases 23\n"
     ]
    }
   ],
   "source": [
    "GrossConversion_x=full.GC[full[\"GC\"]==1].count()\n",
    "NetConversion_x=full.NC[full[\"NC\"]==1].count()\n",
    "n=full.NC.count()\n",
    "print(\"No. of cases for GC:\",GrossConversion_x,'\\n',\n",
    "      \"No. of cases for NC:\",NetConversion_x,'\\n',\n",
    "      \"No. of total cases\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Sign Test\n",
    "According to the binomial distribution with $p=0.5$ and $n=$total number of days; we want to now the probability of $x$ days being a success (higher metric value in experiment). Because we are doing a two-tailed test we want to double this probability and once we have we can call it the $p-value$ and compare it to our $\\alpha$. If the $p-value$ is greater than the $\\alpha$ the result is not significant and vice-versa.<br>\n",
    "<center><font size=\"4\"> $p(successes )=\\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}$ </font></center>\n",
    "Recall that a $p-value$ is the probability of observing a test statistic as or more extreme than that observed. If we observed 2 days like that, the $p-value$ for the test is: $p-value = P(x <= 2)$. We only need to remember the following:<br>\n",
    "<center>$P(x<=2)=P(0)+P(1)+P(2)$.</center><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first a function for calculating probability of x=number of successes\n",
    "def get_prob(x,n):\n",
    "    p=round(mt.factorial(n)/(mt.factorial(x)*mt.factorial(n-x))*0.5**x*0.5**(n-x),4)\n",
    "    return p\n",
    "#next a function to compute the pvalue from probabilities of maximum x\n",
    "def get_2side_pvalue(x,n):\n",
    "    p=0\n",
    "    for i in range(0,x+1):\n",
    "        p=p+get_prob(i,n)\n",
    "    return 2*p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to conduct the sign test itself: we will calculate the p-value for each metric, using the counts `GrossConversion_x`,`NetConversion_x` and `n` and the function `get_2side_pvalue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrossConversion Change is significant if 0.0026000000000000003 is smaller than 0.05\n",
      "NetConversion Change is significant if 0.6774 is smaller than 0.05\n"
     ]
    }
   ],
   "source": [
    "print (\"GrossConversion Change is significant if\",get_2side_pvalue(GrossConversion_x,n),\"is smaller than 0.05\")\n",
    "print (\"NetConversion Change is significant if\",get_2side_pvalue(NetConversion_x,n),\"is smaller than 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
